---
title: "FRAM OBSERVATORY -- Remote Access Samplers -- Processing of 18S rRNA amplicons (run CW5KV)"
---

This markdown describes the processing of 18S rRNA amplicon sequences, originating from continuous year-round sampling by "Remote Access Samplers" in the framework of the LTER  "Frontiers in Arctic Marine Monitoring" (FRAM).

Primer clipping using *Cutadapt* 

```{console}

cd /isibhv/projects/FRAMdata/FRAM_MicrObs/WaterCol_RAS_1620/eukaryotes/CW5KV/
mkdir Original
cd Original

# Use custom script to fetch fastqs from TapeArchive
# Files are listed in "files2cp.txt"
/global/AWIsoft/bio/scripts/getFastqsFromTape.sh ../files2cp.txt

# Some samples were re-sequenced due to Miseq error
# Filenames are still the same; except run-ID
# we only keep tose from the corretc run CW5KV
# others from run CG63D are deleted
rm *CG63D*

# Use custom script to remove MiSeq-ID from filenames
/global/AWIsoft/bio/scripts/renameFastqs.sh
cd ..

######################################

module load bio/cutadapt/3.2

# Use custom script
bash ./../../../software/cutadapt.sh ./Original GCGGTAATTCCAGCTCCAA ACTTTCGTTCTTGATYRR

# test rename
cd Clipped
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; echo -e $i $nname; done

# if looking OK - execute:  
for i in *fastq.gz; do nname=`echo $i | awk '{gsub(/S[0-9]{1,3}_L001/,"clip");print}'`; mv $i $nname; done

# write sampleNames for dada
ls -1 *R1_001.fastq.gz | sed 's/_R1_001\.fastq.gz//' > ../sampleNames.txt

```

*DADA2 amplicon analysis*

# done in RStudio within AWI-VM
# provided IP address opened in browser
# adjust for your own system 

```{r, eval=F}

require(dada2)
require(ShortRead)
require(ggplot2)
require(gridExtra)

##########################################

# setwd 
setwd("/isibhv/projects/FRAMdata/FRAM_MicrObs/WaterCol_RAS_1620/eukaryotes/CW5KV")

# list files
path <- "/isibhv/projects/FRAMdata/FRAM_MicrObs/WaterCol_RAS_1620/eukaryotes/CW5KV/Clipped"
fns <- list.files(path)
fns

# ensure fwd/rev reads  in same order
fnFs <- sort(list.files(path, pattern="_R1_001.fastq.gz"))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq.gz"))

# Define sample names
sampleNames <- sort(read.table(
  "sampleNames.txt", 
  h=F, stringsAsFactors=F)$V1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRs <- file.path(path, fnRs)

#################################

# Quality check
QualityProfileFs <- list()
for(i in 1:length(fnFs)) {QualityProfileFs[[i]] <- list()
  QualityProfileFs[[i]][[1]] <- plotQualityProfile(fnFs[i])}
pdf("QualityProfileForward.pdf")
for(i in 1:length(fnFs)) {do.call("grid.arrange", 
    QualityProfileFs[[i]])}
dev.off()
rm(QualityProfileFs)

QualityProfileRs <- list()
for(i in 1:length(fnRs)) {
  QualityProfileRs[[i]] <- list()
  QualityProfileRs[[i]][[1]] <- plotQualityProfile(
    fnRs[i])}
pdf("QualityProfileReverse.pdf")
for(i in 1:length(fnRs)) {do.call("grid.arrange", 
  QualityProfileRs[[i]])}
dev.off()
rm(QualityProfileRs)
# looking OK

# Prepare for fastq filtering
filt_path <- file.path(path, "../Filtered")
if(!file_test("-d", filt_path)) dir.create(filt_path)
filtFs <- file.path(
  filt_path, paste0(sampleNames, "_F_filt.fastq"))
filtRs <- file.path(
  filt_path, paste0(sampleNames, "_R_filt.fastq"))

#################################

# Filter
out <- filterAndTrim(
  fnFs, 
  filtFs, 
  fnRs, 
  filtRs,
  truncLen = c(250, 200),
  maxN = 0,
  minQ = 2,
  maxEE = c(3, 3), 
  truncQ = 0, 
  rm.phix = T,
  compress = F,
  multithread = 12)

# Should retain >70% -- 0.7 here -- acceptable
head(out)
summary(out[, 2]/out[, 1])

#################################

# Quality check 
QualityProfileFs.filt <- list()
for(i in 1:length(filtFs)) {
  QualityProfileFs.filt[[i]] <- list()
  QualityProfileFs.filt[[i]][[1]] <- plotQualityProfile(
    filtFs[i])}
pdf("QualityProfileForwardFiltered.pdf")
for(i in 1:length(filtFs)) {do.call("grid.arrange", 
    QualityProfileFs.filt[[i]])}
dev.off()
rm(QualityProfileFs.filt)

QualityProfileRs.filt <- list()
for(i in 1:length(filtRs)) {
  QualityProfileRs.filt[[i]] <- list()
  QualityProfileRs.filt[[i]][[1]] <- plotQualityProfile(
    filtRs[i])}
pdf("QualityProfileReverseFiltered.pdf")
for(i in 1:length(filtRs)) {  do.call("grid.arrange", 
    QualityProfileRs.filt[[i]])}
dev.off()
rm(QualityProfileRs.filt)

#################################

# Learn errors 
errF <- learnErrors(
  filtFs, multithread=12, 
  randomize=T, verbose=1, MAX_CONSIST=20)
errR <- learnErrors(
  filtRs, multithread=12, 
  randomize=T, verbose=1, MAX_CONSIST=20)

# Plot error profiles
pdf("ErrorProfiles.pdf")
plotErrors(errF, nominalQ = T)
plotErrors(errR, nominalQ = T)
dev.off()
# convergence after 5-6 rounds - ok!
# few outliers outside black line - ok!

# Dereplication 
derepFs <- derepFastq(filtFs, verbose=T)
derepRs <- derepFastq(filtRs, verbose=T)

# Name the derep-class objects by the sample names
names(derepFs) <- sampleNames
names(derepRs) <- sampleNames

# Denoising
dadaFs <- dada(
  derepFs, err=errF, multithread=24, pool=T)
dadaRs <- dada(
  derepRs, err=errR, multithread=24, pool=T)

#################################

# Read merging
mergers <- mergePairs(
  dadaFs, 
  derepFs, 
  dadaRs,
  derepRs,
  minOverlap=20,
  verbose=T,
  propagateCol = c(
    "birth_fold", 
    "birth_ham"))

# Create sequence table
seqtab <- makeSequenceTable(mergers)
dim(seqtab) # 12469 sequences
saveRDS(seqtab, 
  "seqtab_euk_CW5KV.rds")

# Summary stats
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(
  dadaFs, getN), sapply(mergers, getN), 
  rowSums(seqtab))
colnames(track) <- c(
  "input","filtered","denoised",
  "merged","tabled")
rownames(track) <- sampleNames
track <- data.frame(track)
head(track)

write.table(track, 
  "dadastats_euk_CW5KV.txt", 
  quote=F, sep="\t")

#################################

save.image("RAS_euk_CW5KV.Rdata")

```

Sequence tables from all RAS amplicons are combined, chimera-checked and assigned taxonomy using the MergeChimTax Rscript.